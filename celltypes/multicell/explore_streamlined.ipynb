{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# path hack for relative import in jupyter notebook\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# LIBRARY GLOBAL MODS\n",
    "CELLTYPES = os.path.dirname(os.path.abspath(''))\n",
    "sys.path.append(CELLTYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import umap\n",
    "import time\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})\n",
    "\n",
    "from utils.file_io import RUNS_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multicell.unsupervised_helper import \\\n",
    "    plotly_express_embedding, generate_control_data, plot_given_multicell, make_dimreduce_object\n",
    "\n",
    "from singlecell.singlecell_linalg import sorted_eig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these set the defaults for modifications introduced in main\n",
    "REDUCER_SEED = 0\n",
    "REDUCER_COMPONENTS = 3\n",
    "VALID_REDUCERS = ['umap', 'tsne', 'pca']\n",
    "REDUCERS_TO_USE = ['umap']\n",
    "assert REDUCERS_TO_USE == ['umap']  # for now, extend later\n",
    "\n",
    "# see defaults: https://umap-learn.readthedocs.io/en/latest/api.html\n",
    "UMAP_KWARGS = {\n",
    "    'random_state': REDUCER_SEED,\n",
    "    'n_components': REDUCER_COMPONENTS,\n",
    "    'metric': 'euclidean',\n",
    "    'init': 'spectral',\n",
    "    'unique': False,\n",
    "    'n_neighbors': 15,\n",
    "    'min_dist': 0.1,\n",
    "    'spread': 1.0,\n",
    "}\n",
    "TSNE_KWARGS = {\n",
    "    'random_state': REDUCER_SEED,\n",
    "    'n_components': REDUCER_COMPONENTS,\n",
    "    'metric': 'euclidean',\n",
    "    'init': 'random',\n",
    "    'perplexity': 30.0,\n",
    "}\n",
    "PCA_KWARGS = {\n",
    "    'n_components': REDUCER_COMPONENTS,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0) Dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) load dataset\n",
    "gamma = 1.0\n",
    "manyruns_dirname = 'Wmaze15_gamma%.2f_10k_p3_M100' % gamma\n",
    "manyruns_path = RUNS_FOLDER + os.sep + 'multicell_manyruns' + os.sep + manyruns_dirname\n",
    "    \n",
    "# Step 0) load data\n",
    "data_subdict = {'label': manyruns_dirname,\n",
    "                'path': manyruns_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) DImension reduction (store in data_subdict object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I:\\Development\\Repositories\\biomodels\\celltypes\\runs\\multicell_manyruns\\Wmaze15_gamma1.00_10k_p3_M100\\aggregate\\X_aggregate_last.npz\n",
      "(10000, 900)\n"
     ]
    }
   ],
   "source": [
    "use_01 = True\n",
    "nsubsample = None\n",
    "\n",
    "# 1) fill out data_subdict (dim reduce)\n",
    "data_subdict = make_dimreduce_object(\n",
    "    data_subdict, \n",
    "    nsubsample=nsubsample, \n",
    "    flag_control=False,\n",
    "    use_01=use_01, \n",
    "    jitter_scale=0.0,\n",
    "    reducers=REDUCERS_TO_USE,\n",
    "    umap_kwargs=UMAP_KWARGS, tsne_kwargs=TSNE_KWARGS, pca_kwargs=PCA_KWARGS,\n",
    "    step=None)\n",
    "#save_dimreduce_object(datasets[idx], fpath)  # save to file (joblib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_subdict.keys())\n",
    "print(data_subdict['algos']['umap'].keys())\n",
    "print(data_subdict['algos']['umap']['embedding'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Visualize umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = RUNS_FOLDER + os.sep + 'explore' + os.sep + 'umap'\n",
    "\n",
    "# 2) visualize data_subdict\n",
    "plotly_express_embedding(data_subdict, \n",
    "                         color_by_index=False, \n",
    "                         as_landscape=False, \n",
    "                         fmod='jupyter', \n",
    "                         show=False, \n",
    "                         dirpath=outdir, \n",
    "                         surf=False, \n",
    "                         step=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and plotting of sample points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\"\"\"\n",
    "NOTES:\n",
    "- kmeans.labels_ will return [cluster_7, cluster_5, ..., cluster_0] -- cluster id for each data point\n",
    "- also have: kmeans.predict([[0, 0], [12, 3]])\n",
    "- also have: kmeans.cluster_centers_\n",
    "\"\"\"\n",
    "\n",
    "#kmeans_highdim = KMeans(n_clusters=8, random_state=0).fit(X)\n",
    "N_CLUSTERS = 8\n",
    "CLUSTER_COLOURS = {0: 'blue', 1: 'red', 2:'green', 3:'purple', 4: 'pink', 5: 'brown', 6: 'gray', 7: 'black'}\n",
    "assert N_CLUSTERS <= len(CLUSTER_COLOURS.keys())\n",
    "\n",
    "kmeans_lowdim = KMeans(n_clusters=N_CLUSTERS, random_state=0).fit(data_subdict['algos']['umap']['embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_to_colour(a):\n",
    "    return CLUSTER_COLOURS[a]\n",
    "\n",
    "\n",
    "kmeans_labels = kmeans_lowdim.labels_ \n",
    "color_vector = [cluster_to_colour(a) for a in kmeans_labels]\n",
    "\n",
    "\n",
    "#clusterstyle = {'color_vector': color_vector, \n",
    "#                'cluster_ids': kmeans_labels.astype('str')}\n",
    "clusterstyle = {'color_vector': color_vector, \n",
    "                'cluster_ids': kmeans_labels,\n",
    "                'order': [str(a) for a in range(N_CLUSTERS)]\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotly_express_embedding(data_subdict, \n",
    "                         color_by_index=False, \n",
    "                         as_landscape=False, \n",
    "                         fmod='jupyter', \n",
    "                         show=False, \n",
    "                         dirpath=outdir, \n",
    "                         surf=False, \n",
    "                         step=None,\n",
    "                         clusterstyle=clusterstyle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 4 ... 4 0 7]\n"
     ]
    }
   ],
   "source": [
    "print(kmeans_lowdim.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kmeans_highdim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-6f73ead8475e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'colours_highdim'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabel_to_colour\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkmeans_highdim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'colours_lowdim'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabel_to_colour\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkmeans_lowdim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kmeans_highdim' is not defined"
     ]
    }
   ],
   "source": [
    "fcontents['colours_highdim'] = [label_to_colour(a) for a in kmeans_highdim.labels_]\n",
    "fcontents['colours_lowdim'] = [label_to_colour(a) for a in kmeans_lowdim.labels_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_plotly_clustered(data_subdict):   \n",
    "    \n",
    "    import plotly.express as px\n",
    "\n",
    "    num_runs = data_subdict['num_runs']\n",
    "    label = data_subdict['label']\n",
    "    embedding = data_subdict['algos']['umap']['embedding']\n",
    "    reducer = data_subdict['algos']['umap']['reducer']\n",
    "    #c = data_subdict['energies'][:, 0]  # range(num_runs)\n",
    "    c = data_subdict['colours_lowdim']\n",
    "\n",
    "    umap_dim = embedding.shape[1]\n",
    "    assert umap_dim in [2,3]\n",
    "    \n",
    "    if umap_dim == 2:\n",
    "        df = pd.DataFrame({'index': range(num_runs),\n",
    "                           'c': c,\n",
    "                           'x': embedding[:,0],\n",
    "                           'y': embedding[:,1]})\n",
    "\n",
    "        fig = px.scatter(df, x='x', y='y',\n",
    "                         color='c',\n",
    "                         title='UMAP of %s dataset' % label,\n",
    "                        )\n",
    "\n",
    "    else:\n",
    "        df = pd.DataFrame({'index': range(num_runs),\n",
    "                       'c': c,\n",
    "                       'x': embedding[:,0],\n",
    "                       'y': embedding[:,1],\n",
    "                       'z': embedding[:,2]})\n",
    "    \n",
    "        fig = px.scatter_3d(df, x='x', y='y', z='z', \n",
    "                            color='c',\n",
    "                            title='UMAP of %s dataset' % label,\n",
    "                           )\n",
    "    fig.write_html(\"umap_plotly_%s_clustered.html\" % label)\n",
    "    fig.show()\n",
    "    \n",
    "def plotly_express_embedding_clustered(data_subdict):\n",
    "    \"\"\"\n",
    "    Supports 2D and 3D embeddings\n",
    "    \"\"\"\n",
    "    \n",
    "    import plotly.express as px\n",
    "\n",
    "\n",
    "    num_runs = data_subdict['num_runs']\n",
    "    label = data_subdict['label']\n",
    "    dirpath = data_subdict['path'] + os.sep + 'dimreduce'\n",
    "    #c = data_subdict['energies'][:, 0]  # range(num_runs)\n",
    "    c = data_subdict['colours_highdim']\n",
    "\n",
    "    \n",
    "    for key, algodict in data_subdict['algos'].items():\n",
    "        algo = key\n",
    "        reducer = algodict['reducer']\n",
    "        embedding = algodict['embedding']\n",
    "\n",
    "        n_components = embedding.shape[1]\n",
    "        assert n_components in [2, 3]\n",
    "\n",
    "        if n_components == 2:\n",
    "            df = pd.DataFrame({'index': range(num_runs),\n",
    "                               'energy': c,\n",
    "                               'x': embedding[:, 0],\n",
    "                               'y': embedding[:, 1]})\n",
    "\n",
    "            fig = px.scatter(df, x='x', y='y',\n",
    "                             color='energy',\n",
    "                             title='%s of %s dataset' % (algo, label))\n",
    "\n",
    "        else:\n",
    "            df = pd.DataFrame({'index': range(num_runs),\n",
    "                               'energy': c,\n",
    "                               'x': embedding[:, 0],\n",
    "                               'y': embedding[:, 1],\n",
    "                               'z': embedding[:, 2]})\n",
    "\n",
    "            fig = px.scatter_3d(df, x='x', y='y', z='z',\n",
    "                                color='energy',\n",
    "                                title='%s of %s dataset' % (algo, label))\n",
    "\n",
    "        if not os.path.exists(dirpath):\n",
    "            os.makedirs(dirpath)\n",
    "        fig.write_html(dirpath + os.sep + \"%s_plotly_%s_clustered.html\" % (algo, label))\n",
    "        fig.show()\n",
    "    return\n",
    "\n",
    "plotly_express_embedding_clustered(fcontents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize arbitrary point in umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_given_multicell(multicell, step_hack, agg_index, outdir):\n",
    "    fpaths = [outdir + os.sep + a for a in\n",
    "              ['agg%d_compOverlap.png' % agg_index,\n",
    "               'agg%d_compProj.png' % agg_index,\n",
    "               'agg%d_ref0_overlap.png' % agg_index]\n",
    "          ]\n",
    "    multicell.step_datadict_update_global(step_hack, fill_to_end=False)\n",
    "    multicell.step_state_visualize(step_hack, fpaths=fpaths)  # visualize\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A: [325, 269, 3918, 5329]\n",
    "# B: [2145, 8616, 6241, 1632]\n",
    "\n",
    "# CHOICES\n",
    "agg_indices = [2145, 8616, 6241, 1632]\n",
    "dataset_label = '0e_10k'\n",
    "outdir = RUNS_FOLDER + os.sep + 'explore' + os.sep + 'B'\n",
    "        \n",
    "# NON-LOOP\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)\n",
    "dataset_index = gamma_vals.index(dataset_label)\n",
    "subdict = datasets[dataset_index]\n",
    "multicell = subdict['multicell_template']\n",
    "\n",
    "for agg_index in agg_indices:\n",
    "    # pull relevant info from subdict\n",
    "    X = subdict['data'][agg_index, :]\n",
    "    step_hack = 0  # TODO care this will break if class has time-varying applied field\n",
    "    multicell.graph_state_arr[:, step_hack] = X[:]\n",
    "    assert np.array_equal(multicell_template.field_applied,\n",
    "                          np.zeros((total_spins, multicell_template.total_steps)))\n",
    "    plot_given_multicell(multicell, step_hack, agg_index, outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D vis attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://www.kaggle.com/scratchpad/notebook163accf2b7/edit\n",
    "\n",
    "import umap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umap_3d_mpl(dataset):\n",
    "    \"\"\"\n",
    "    TOO SLOW -- use plotly instead\n",
    "    \"\"\"\n",
    "    embedding = dataset['embedding']\n",
    "    num_runs = embedding.shape[0]\n",
    "    xvec = embedding[:,0]\n",
    "    yvec = embedding[:,1]\n",
    "    zvec = embedding[:,2]\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    marker = 'o' # '^'\n",
    "    for idx in range(num_runs):\n",
    "        ax.scatter(xvec[idx], yvec[idx], zvec[idx], marker=marker)\n",
    "\n",
    "    ax.set_xlabel('u1')\n",
    "    ax.set_ylabel('u2')\n",
    "    ax.set_zlabel('u3')\n",
    "    ax.set_title(\"umap_%s\" % dataset['label'])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def umap_plotly_express(data_subdict):\n",
    "    \"\"\"\n",
    "    Supports 2D and 3D embeddings\n",
    "    \"\"\"\n",
    "    \n",
    "    num_runs = data_subdict['num_runs']\n",
    "    label = data_subdict['label']\n",
    "    embedding = data_subdict['embedding']\n",
    "    reducer = data_subdict['reducer']\n",
    "    c = data_subdict['energies'][:, 0]  # range(num_runs)\n",
    "\n",
    "    umap_dim = embedding.shape[1]\n",
    "    assert umap_dim in [2,3]\n",
    "    \n",
    "    if umap_dim == 2:\n",
    "        df = pd.DataFrame({'index': range(num_runs),\n",
    "                           'energy': c,\n",
    "                           'x': embedding[:,0],\n",
    "                           'y': embedding[:,1]})\n",
    "\n",
    "        fig = px.scatter(df, x='x', y='y',\n",
    "                         color='energy',\n",
    "                         title='UMAP of %s dataset' % label,\n",
    "                        )\n",
    "\n",
    "    else:\n",
    "        df = pd.DataFrame({'index': range(num_runs),\n",
    "                       'energy': c,\n",
    "                       'x': embedding[:,0],\n",
    "                       'y': embedding[:,1],\n",
    "                       'z': embedding[:,2]})\n",
    "    \n",
    "        fig = px.scatter_3d(df, x='x', y='y', z='z', \n",
    "                            color='energy',\n",
    "                            title='UMAP of %s dataset' % label,\n",
    "                           )\n",
    "    fig.write_html(\"umap_plotly_%s.html\" % label)\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "def umap_plotly_general(dataset):\n",
    "    \"\"\"\"\n",
    "    TODO: implement this more general version of the 'express' code umap_plotly_express() -- see docs\n",
    "    Supports 2D and 3D embeddings\n",
    "    \"\"\"\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    # Helix equation\n",
    "    t = np.linspace(0, 10, 50)\n",
    "    x, y, z = np.cos(t), np.sin(t), t\n",
    "\n",
    "    fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z,\n",
    "                                       mode='markers')])\n",
    "    fig.show()\n",
    "\n",
    "#umap_3d_plotly_generic(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(gamma_vals)):\n",
    "    umap_plotly_express(datasets[i])\n",
    "umap_plotly_express(datasets[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K means on umap to get labels for points in each cluster**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare lowdim kmeans labels with statistics in original space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans_lowdim.labels_)\n",
    "\n",
    "blue_indices = [idx for idx, i in enumerate(kmeans_lowdim.labels_) if i == 0]\n",
    "red_indices = [idx for idx, i in enumerate(kmeans_lowdim.labels_) if i == 1]\n",
    "fcontents['data_blue'] = X_pm1[blue_indices, :] \n",
    "fcontents['data_red'] = X_pm1[red_indices, :]\n",
    "\n",
    "print(fcontents['data_blue'].shape)\n",
    "print(fcontents['data_red'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing UNIQUE flag for umap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsupervised_helper import *\n",
    "\n",
    "build_dimreduce_dicts = True\n",
    "add_control_data = False\n",
    "vis_all = True\n",
    "pca_assess = False\n",
    "nsubsample = None  # None or an int\n",
    "\n",
    "# Step 0) which 'manyruns' dirs to work with\n",
    "#gamma_list = [0.0, 0.05, 0.1, 0.2, 1.0, 2.0, 20.0]\n",
    "gamma_list = [20.0]\n",
    "#gamma_list = [20.0]\n",
    "#manyruns_dirnames = ['Wrandom1_gamma%.2f_10k_fixedorder_ferro' % a for a in gamma_list]\n",
    "#manyruns_dirnames = ['Wrandom0_gamma%.2f_10k_p3_M100' % a for a in gamma_list]\n",
    "manyruns_dirnames = ['Wrandom1_gamma%.2f_10k_fixedorder_p3_M100' % a for a in gamma_list]\n",
    "\n",
    "manyruns_paths = [RUNS_FOLDER + os.sep + 'multicell_manyruns' + os.sep + dirname\n",
    "                  for dirname in manyruns_dirnames]\n",
    "\n",
    "# Step 1) umap (or other dim reduction) kwargs\n",
    "if any([build_dimreduce_dicts, add_control_data, vis_all, pca_assess]):\n",
    "    for n_components in [2, 3]:\n",
    "        #n_components = 3\n",
    "        pca_kwargs = PCA_KWARGS.copy()\n",
    "        pca_kwargs['n_components'] = n_components  # TODO don't need to spec 'live', can embed later?\n",
    "        umap_kwargs = UMAP_KWARGS.copy()\n",
    "        umap_kwargs['n_components'] = n_components  # TODO don't need to spec 'live', can embed later?\n",
    "        tsne_kwargs = TSNE_KWARGS.copy()\n",
    "        tsne_kwargs['n_components'] = n_components  # TODO don't need to spec 'live', can embed later?\n",
    "        # modify pca settings\n",
    "        # modify umap settings\n",
    "        umap_kwargs['unique'] = True\n",
    "        #umap_kwargs['n_neighbors'] = 100\n",
    "        #umap_kwargs['min_dist'] = 0.1\n",
    "        #umap_kwargs['spread'] = 1.0\n",
    "        #umap_kwargs['metric'] = 'euclidean'\n",
    "        # modify tsne settings\n",
    "        tsne_kwargs['perplexity'] = 100\n",
    "\n",
    "        # Modify filename suffix for dimreduce pkl and plots\n",
    "        fmod = '_F=' + '+'.join(REDUCERS_TO_USE)\n",
    "        fmod += '_dim%d_seed%d' % (umap_kwargs['n_components'], umap_kwargs['random_state'])\n",
    "        if nsubsample is not None:\n",
    "            fmod += '_nn%d' % nsubsample\n",
    "        if 'umap' in REDUCERS_TO_USE:\n",
    "            if umap_kwargs['metric'] != 'euclidean':\n",
    "                fmod += '_%s' % umap_kwargs['metric']\n",
    "            if umap_kwargs['init'] != 'spectral':\n",
    "                fmod += '_%s' % umap_kwargs['init']\n",
    "            if umap_kwargs['n_neighbors'] != 15:\n",
    "                fmod += '_nbor%d' % umap_kwargs['n_neighbors']\n",
    "            if umap_kwargs['min_dist'] != 0.1:\n",
    "                fmod += '_dist%.2f' % umap_kwargs['min_dist']\n",
    "            if umap_kwargs['spread'] != 1.0:\n",
    "                fmod += '_spread%.2f' % umap_kwargs['spread']\n",
    "            if umap_kwargs['unique']:\n",
    "                fmod += '_unique'\n",
    "        if 'tsne' in REDUCERS_TO_USE:\n",
    "            if tsne_kwargs['perplexity'] != 30.0:\n",
    "                fmod += '_perplex%.2f' % tsne_kwargs['perplexity']\n",
    "\n",
    "        # Step 2) make/load data\n",
    "        datasets = {i: {'label': manyruns_dirnames[i],\n",
    "                        'path': manyruns_paths[i]}\n",
    "                    for i in range(len(manyruns_dirnames))}\n",
    "\n",
    "        for idx in range(len(manyruns_dirnames)):\n",
    "            fpath = manyruns_paths[idx] + os.sep + 'dimreduce' + os.sep + 'dimreduce%s.z' % fmod\n",
    "            if os.path.isfile(fpath):\n",
    "                print('Exists already, loading: %s' % fpath)\n",
    "                fcontents = joblib.load(fpath)  # just load file if it exists\n",
    "                datasets[idx] = fcontents\n",
    "            else:\n",
    "                print('Dim. reduction on manyruns: %s' % manyruns_dirnames[idx])\n",
    "                datasets[idx] = make_dimreduce_object(\n",
    "                    datasets[idx], nsubsample=nsubsample, flag_control=False,\n",
    "                    umap_kwargs=umap_kwargs, tsne_kwargs=tsne_kwargs, pca_kwargs=pca_kwargs)\n",
    "                save_dimreduce_object(datasets[idx], fpath)  # save to file (joblib)\n",
    "\n",
    "        if add_control_data:\n",
    "            print('adding control data...')\n",
    "            total_spins_0 = datasets[0]['total_spins']\n",
    "            num_runs_0 = datasets[0]['num_runs']\n",
    "\n",
    "            # add control data into the dict of datasets\n",
    "            control_X = generate_control_data(total_spins_0, num_runs_0)\n",
    "            control_folder = RUNS_FOLDER + os.sep + 'multicell_manyruns' + os.sep + 'control'\n",
    "            control_fpath = control_folder + os.sep + \\\n",
    "                            'dimreduce' + os.sep + 'dimreduce%s.z' % fmod\n",
    "\n",
    "            datasets[-1] = {\n",
    "                'data': control_X,\n",
    "                'label': 'control (coin-flips)',\n",
    "                'num_runs': num_runs_0,\n",
    "                'total_spins': total_spins_0,\n",
    "                'energies': np.zeros((num_runs_0, 5)),\n",
    "                'path': control_folder\n",
    "            }\n",
    "            datasets[-1] = make_dimreduce_object(\n",
    "                datasets[-1], flag_control=True, nsubsample=nsubsample,\n",
    "                umap_kwargs=umap_kwargs, tsne_kwargs=tsne_kwargs, pca_kwargs=pca_kwargs)\n",
    "            save_dimreduce_object(datasets[-1], control_fpath)  # save to file (joblib)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing plotly surface plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "# Read data from a csv\n",
    "z_data = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/api_docs/mt_bruno_elevation.csv')\n",
    "\n",
    "#print(z_data['x'])\n",
    "data_top = z_data.head()  \n",
    "print(data_top)\n",
    "print(z_data.shape)\n",
    "print(z_data.values.shape)\n",
    "print(type(z_data.values))\n",
    "a = z_data.values\n",
    "a.reshape(1, len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Surface(z=z_data.values)])\n",
    "\n",
    "fig.update_layout(title='Mt Bruno Elevation', autosize=False,\n",
    "                  width=500, height=500,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single 2D+E landscape**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "\n",
    "pick = 1\n",
    "\n",
    "use_plotly = True\n",
    "\n",
    "manyruns_path = manyruns_paths[pick]\n",
    "print(pick, gamma_list[pick], manyruns_path)\n",
    "fpath_energy = manyruns_path + os.sep + 'aggregate' + os.sep + 'X_energy_last.npz'\n",
    "X_energies = np.load(fpath_energy)['arr_0'].T  # umap wants transpose (?)\n",
    "energies = X_energies[:nn, 0]\n",
    "\n",
    "X = aligned_mapper.embeddings_[pick]\n",
    "print(X.shape)\n",
    "\n",
    "print(X[2602,:])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "# ===============================\n",
    "if use_plotly:\n",
    "    clabel = 'energies'\n",
    "    df = pd.DataFrame({'index': range(nn),\n",
    "                        clabel: energies,\n",
    "                       'x': X[:, 0],\n",
    "                       'y': X[:, 1],\n",
    "                       'z': energies})\n",
    "\n",
    "    fig = px.scatter_3d(df, x='x', y='y', z='z',\n",
    "                        color=clabel,\n",
    "                        title='jupyter',\n",
    "                        hover_name='index')\n",
    "    fig.show()\n",
    "else:\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(X[:,0], X[:,1], energies, c=energies, cmap='Spectral_r')\n",
    "    ax.set_xlabel('X Label')\n",
    "    ax.set_ylabel('Y Label')\n",
    "    ax.set_zlabel('Z Label')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot specific points from index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multicell.unsupervised_helper import plot_given_multicell\n",
    "\n",
    "\n",
    "agg_indices = [911]\n",
    "outdir = RUNS_FOLDER + os.sep + 'explore' + os.sep + 'plot_specific_points'\n",
    "\n",
    "# where is the data?\n",
    "step = None\n",
    "#dirname = 'Wrandom0_gamma0.20_10k_periodic_fixedorderV3_p3_M100'\n",
    "dirname = 'Wrandom0_gamma1.00_10k_periodic_fixedorderV3_p3_M100'\n",
    "\n",
    "\n",
    "#step = 14\n",
    "#dirname = 'beta2.05_Wrandom0_gamma0.20_10k_periodic_fixedorderV3_p3_M100'\n",
    "\n",
    "manyruns_path = RUNS_FOLDER + os.sep + 'multicell_manyruns' + os.sep + dirname\n",
    "fpath_pickle = manyruns_path + os.sep + 'multicell_template.pkl'\n",
    "with open(fpath_pickle, 'rb') as pickle_file:\n",
    "    multicell = pickle.load(pickle_file)  # unpickling multicell object\n",
    "\n",
    "for agg_index in agg_indices:  \n",
    "    #smod = ''\n",
    "    smod = '_last'\n",
    "    if step is not None:\n",
    "        smod = '_%d' % step\n",
    "    \n",
    "    agg_dir = manyruns_path + os.sep + 'aggregate'\n",
    "    fpath_state = agg_dir + os.sep + 'X_aggregate%s.npz' % smod\n",
    "    fpath_energy = agg_dir + os.sep + 'X_energy%s.npz' % smod\n",
    "    fpath_pickle = manyruns_path + os.sep + 'multicell_template.pkl'\n",
    "    print(fpath_state)\n",
    "    X = np.load(fpath_state)['arr_0'].T  # umap wants transpose\n",
    "    X_state = X[agg_index, :]\n",
    "    \n",
    "    step_hack = 0  # TODO care this will break if class has time-varying applied field\n",
    "    multicell.graph_state_arr[:, step_hack] = X_state[:]\n",
    "    #assert np.array_equal(multicell_template.field_applied, np.zeros((total_spins, multicell_template.total_steps)))\n",
    "    plot_given_multicell(multicell, step_hack, agg_index, outdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check indiv lattice states**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.file_io import run_subdir_setup, RUNS_FOLDER, INPUT_FOLDER\n",
    "from multicell.graph_helper import state_load\n",
    "from multicell.graph_adjacency import lattice_square_loc_to_int\n",
    "from singlecell.singlecell_simsetup import singlecell_simsetup\n",
    "\n",
    "replot_dir = RUNS_FOLDER + os.sep + 'explore' + os.sep + 'replot'\n",
    "\n",
    "sidelength = 20\n",
    "curated = True\n",
    "random_mem = False        # TODO incorporate seed in random XI in simsetup/curated\n",
    "random_W = False          # TODO incorporate seed in random W in simsetup/curated\n",
    "W_override_path = INPUT_FOLDER + os.sep + 'manual_WJ' + os.sep + 'simsetup_W_9_maze.txt'\n",
    "simsetup_main = singlecell_simsetup(\n",
    "    unfolding=True, random_mem=random_mem, random_W=random_W, curated=curated, housekeeping=0)\n",
    "if W_override_path is not None:\n",
    "    print('Note: in main, overriding W from file...')\n",
    "    explicit_W = np.loadtxt(W_override_path, delimiter=',')\n",
    "    simsetup_main['FIELD_SEND'] = explicit_W\n",
    "print(\"simsetup checks:\")\n",
    "print(\"\\tsimsetup['N'],\", simsetup_main['N'])\n",
    "print(\"\\tsimsetup['P'],\", simsetup_main['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [a for a in os.listdir(replot_dir) if a[-4:] == '.npz']\n",
    "fpaths = [replot_dir + os.sep + a for a in fnames]\n",
    "print(fpaths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fpaths[9])\n",
    "X = state_load(fpaths[9], cells_as_cols=True, num_genes=None, num_cells=None, txt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = (0,-3)\n",
    "node_idx = lattice_square_loc_to_int(loc, sidelength)\n",
    "cellstate = X[:, node_idx]\n",
    "print(cellstate)\n",
    "print(np.dot(simsetup_main['XI'].T, cellstate)/9.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turquoise = [30, 223, 214]\n",
    "\n",
    "white = [255,255,255]\n",
    "soft_grey = [225, 220, 222]\n",
    "soft_grey_alt1 = [206, 199, 182]\n",
    "soft_grey_alt2 = [219, 219, 219]\n",
    "beige = [250, 227, 199]\n",
    "\n",
    "soft_blue = [148, 210, 226]\n",
    "soft_blue_alt1 = [58, 128, 191]\n",
    "\n",
    "soft_red = [192, 86, 64]\n",
    "soft_red_alt1 = [240, 166, 144]\n",
    "soft_red_alt2 = [255, 134, 113]\n",
    "\n",
    "soft_yellow = [237, 209, 112]\n",
    "\n",
    "soft_orange = [250, 173, 63]\n",
    "soft_orange_alt1 = [248, 200, 140]\n",
    "\n",
    "soft_green = [120, 194, 153]\n",
    "sharp_green = [142, 200, 50]\n",
    "\n",
    "soft_purple = [177, 156, 217]\n",
    "\n",
    "soft_grey_norm = np.array(soft_grey) / 255.0\n",
    "\n",
    "color_anchor_beige = np.array(beige) / 255.0\n",
    "color_anchor_white = np.array(white) / 255.0\n",
    "color_anchor = color_anchor_white\n",
    "\n",
    "\n",
    "#color_A_pos = np.array(soft_blue_alt1) / 255.0\n",
    "color_A_pos = np.array(soft_blue) / 255.0\n",
    "color_A_neg = np.array(soft_orange) / 255.0\n",
    "\n",
    "color_B_pos = np.array(soft_red) / 255.0\n",
    "color_B_neg = np.array(soft_green) / 255.0\n",
    "\n",
    "color_C_pos = np.array(soft_yellow) / 255.0\n",
    "color_C_neg = np.array(soft_purple) / 255.0\n",
    "\n",
    "def linear_interpolate(val, c2, c1=color_anchor):\n",
    "    eps = 1e-4\n",
    "    assert 0.0 <= val <= 1.0 + eps\n",
    "    cout = c1 + val * (c2 - c1)\n",
    "    return cout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_arr_color(color):\n",
    "    q = np.zeros((10,10,3))\n",
    "    q[:,:,0] += color[0]\n",
    "    q[:,:,1] += color[1]\n",
    "    q[:,:,2] += color[2]\n",
    "    return q\n",
    "\n",
    "fig, axarr = plt.subplots(1,3)\n",
    "a = np.array([color_A_pos]).reshape(1,1,3)\n",
    "axarr[0].imshow(a)\n",
    "b = np.array([color_B_pos]).reshape(1,1,3)\n",
    "axarr[1].imshow(b)\n",
    "c = np.array([color_C_pos]).reshape(1,1,3)\n",
    "axarr[2].imshow(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axarr = plt.subplots(1,3)\n",
    "colour_mix = linear_interpolate(0.3, color_A_pos, c1=color_B_pos)\n",
    "a = np.array([colour_mix]).reshape(1,1,3)\n",
    "axarr[0].imshow(a)\n",
    "\n",
    "colour_mix = linear_interpolate(0.3, color_A_pos, c1=color_C_pos)\n",
    "b = np.array([colour_mix]).reshape(1,1,3)\n",
    "axarr[1].imshow(b)\n",
    "\n",
    "colour_mix = linear_interpolate(0.3, color_B_pos, c1=color_C_pos)\n",
    "c = np.array([colour_mix]).reshape(1,1,3)\n",
    "axarr[2].imshow(c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(soft_purple)/255.0\n",
    "b = np.array(soft_green)/255.0\n",
    "c = np.array(soft_orange)/255.0\n",
    "\n",
    "amount = np.sqrt(0.11)\n",
    "\n",
    "fig, axarr = plt.subplots(1,3)\n",
    "colour_mix = linear_interpolate(amount, a, c1=color_anchor_white)\n",
    "axarr[0].imshow(np.array([colour_mix]).reshape(1,1,3))\n",
    "\n",
    "colour_mix = linear_interpolate(amount, b, c1=color_anchor_white)\n",
    "axarr[1].imshow(np.array([colour_mix]).reshape(1,1,3))\n",
    "\n",
    "colour_mix = linear_interpolate(amount, c, c1=color_anchor_white)\n",
    "axarr[2].imshow(np.array([colour_mix]).reshape(1,1,3))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual UMAP plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import umap\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})\n",
    "\n",
    "from singlecell.singlecell_linalg import sorted_eig\n",
    "from utils.file_io import RUNS_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multicell.unsupervised_helper import make_dimreduce_object, save_dimreduce_object\n",
    "\n",
    "def plotly_express_embedding_LOCAL(data_subdict, color_by_index=False, as_landscape=False,\n",
    "                             fmod='', show=False, dirpath=None, surf=False, step=None):\n",
    "    \"\"\"\n",
    "    Supports 2D and 3D embeddings\n",
    "    color_by_index: for troubleshooting, colors the points according to their array position\n",
    "        if False (default), color by energy instead\n",
    "    \"\"\"\n",
    "    # colormaps here: https://plotly.com/python/builtin-colorscales/\n",
    "    fmod += '_jupyter'\n",
    "\n",
    "    num_runs = data_subdict['num_runs']\n",
    "    label = data_subdict['label']\n",
    "    if dirpath is None:\n",
    "        dirpath = data_subdict['path'] + os.sep + 'dimreduce'\n",
    "    if not os.path.exists(dirpath):\n",
    "        os.makedirs(dirpath)\n",
    "\n",
    "    smod = ''\n",
    "    if step is not None:\n",
    "        smod = ' (step %d)' % step\n",
    "\n",
    "    if color_by_index:\n",
    "        c = np.arange(num_runs)\n",
    "        fmod += '_cIndex'\n",
    "        clabel = 'index'\n",
    "    else:\n",
    "        c = data_subdict['energies'][:, 0]  # range(num_runs)\n",
    "        clabel = 'energy'\n",
    "\n",
    "    for key, algodict in data_subdict['algos'].items():\n",
    "        algo = key\n",
    "        embedding = algodict['embedding']\n",
    "\n",
    "        n_components = embedding.shape[1]\n",
    "        assert n_components in [2, 3]\n",
    "\n",
    "        plot_title = '%s of %s dataset%s' % (algo, label, smod)\n",
    "        plot_path = dirpath + os.sep + \"%s_plotly_%s%s\" % (algo, label, fmod)\n",
    "\n",
    "        if not as_landscape:\n",
    "            if n_components == 2:\n",
    "                df = pd.DataFrame({'index': range(num_runs),\n",
    "                                   clabel: c,\n",
    "                                   'x': embedding[:, 0],\n",
    "                                   'y': embedding[:, 1]})\n",
    "\n",
    "                fig = px.scatter(df, x='x', y='y',\n",
    "                                 color=clabel,\n",
    "                                 title=plot_title,\n",
    "                                 hover_name='index')\n",
    "                fig.update_layout({\n",
    "                    'plot_bgcolor': 'rgba(0,0,0,0)',\n",
    "                    'paper_bgcolor': 'rgba(0,0,0,0)'})\n",
    "\n",
    "            else:\n",
    "                df = pd.DataFrame({'index': range(num_runs),\n",
    "                                   clabel: c,\n",
    "                                   'x': embedding[:, 0],\n",
    "                                   'y': embedding[:, 1],\n",
    "                                   'z': embedding[:, 2]})\n",
    "\n",
    "                fig = px.scatter_3d(df, x='x', y='y', z='z',\n",
    "                                    color=clabel,\n",
    "                                    title=plot_title,\n",
    "                                    hover_name='index')\n",
    "\n",
    "        else:\n",
    "            plot_title += ' landscape'\n",
    "            plot_path += '_landscape'\n",
    "            df = pd.DataFrame({'index': range(num_runs),\n",
    "                               clabel: c,\n",
    "                               'x': embedding[:, 0],\n",
    "                               'y': embedding[:, 1],\n",
    "                               'z': data_subdict['energies'][:, 0]})\n",
    "            if surf:\n",
    "                plot_title += ' surface'\n",
    "                plot_path += 'Surf'\n",
    "\n",
    "                # SKETCHY: assumes Z = X * Y in shape\n",
    "                # - will make Z = all zeros except z_i on diag\n",
    "                \"\"\"\n",
    "                xx = df['x']\n",
    "                yy = df['y']\n",
    "                zz = df['z']\n",
    "\n",
    "                xx = xx[0:1000]\n",
    "                yy = yy[0:1000]\n",
    "                zz = zz[0:1000]\n",
    "\n",
    "                zmax = np.max(zz)\n",
    "                buffer = 0.1 * np.abs(zmax)\n",
    "                zmax += buffer\n",
    "                Z = np.zeros((xx.size, yy.size))\n",
    "                np.fill_diagonal(Z, zz)\n",
    "\n",
    "                fig = go.Figure(data=[go.Surface(\n",
    "                    z=Z, x=zz, y=yy)\n",
    "                ])\n",
    "                fig.update_layout(title=plot_title)\n",
    "                \"\"\"\n",
    "                # Regular trisurf approach (ugly)\n",
    "                u = embedding[:, 0]\n",
    "                v = embedding[:, 1]\n",
    "\n",
    "                from scipy.spatial import Delaunay\n",
    "\n",
    "                points2D = np.vstack([u, v]).T\n",
    "                tri = Delaunay(points2D)\n",
    "                simplices = tri.simplices\n",
    "\n",
    "                fig = ff.create_trisurf(\n",
    "                    x=df['x'], y=df['y'], z=df['z'],\n",
    "                    colormap=\"Thermal\",\n",
    "                    simplices=simplices,\n",
    "                    title=plot_title)\n",
    "\n",
    "            else:\n",
    "                fig = px.scatter_3d(df, x='x', y='y', z='z',\n",
    "                                    color=clabel,\n",
    "                                    title=plot_title,\n",
    "                                    hover_name='index')\n",
    "\n",
    "        fig.write_html(plot_path + '.html')\n",
    "        fig.write_image(plot_path + '.png')\n",
    "        if show:\n",
    "            fig.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these set the defaults for modifications introduced in main\n",
    "REDUCER_SEED = 100\n",
    "REDUCER_COMPONENTS = 3\n",
    "#REDUCERS_TO_USE = ['pca']\n",
    "#REDUCERS_TO_USE = ['tsne']\n",
    "REDUCERS_TO_USE = ['umap']\n",
    "#REDUCERS_TO_USE = ['umap', 'tsne', 'pca']\n",
    "#VALID_REDUCERS = ['umap', 'tsne', 'pca']\n",
    "\n",
    "# see defaults: https://umap-learn.readthedocs.io/en/latest/api.html\n",
    "UMAP_KWARGS = {\n",
    "    'random_state': REDUCER_SEED,\n",
    "    'n_components': REDUCER_COMPONENTS,\n",
    "    'metric': 'euclidean',\n",
    "    'init': 'spectral',\n",
    "    'unique': False,\n",
    "    'n_neighbors': 15,\n",
    "    'min_dist': 0.1,\n",
    "    'spread': 1.0,\n",
    "}\n",
    "TSNE_KWARGS = {\n",
    "    'random_state': REDUCER_SEED,\n",
    "    'n_components': REDUCER_COMPONENTS,\n",
    "    'metric': 'euclidean',\n",
    "    'init': 'random',\n",
    "    'perplexity': 30.0,\n",
    "}\n",
    "PCA_KWARGS = {\n",
    "    'n_components': REDUCER_COMPONENTS,\n",
    "}\n",
    "\n",
    "\n",
    "# main flags\n",
    "build_dimreduce_dicts = True\n",
    "add_control_data = False\n",
    "vis_all = True\n",
    "pca_assess = False\n",
    "plot_specific_points = False\n",
    "check_evals = False\n",
    "\n",
    "# data process settings6\n",
    "use_01 = True\n",
    "jitter_scale = 0  #1e-4\n",
    "nsubsample = None  # None or an int\n",
    "\n",
    "# Step 0) which 'manyruns' dirs to work with\n",
    "#gamma_list = [0.0, 0.05, 0.06, 0.07, 0.08, 0.09, 0.10, 0.15, 0.20, 0.4, 0.6, 0.8, 0.9, 1.0, 20.0]\n",
    "gamma_list = [20.0]\n",
    "\n",
    "#gamma_list = [0.0, 0.2]\n",
    "# gamma_list = [2.0, 20.0]\n",
    "\n",
    "step_list = [None]\n",
    "# step_list = [0.0, 10.0]  # list of [None] or list of steps\n",
    "#step_list = [0, 1, 2, 3] + list(np.arange(4, 20, 5))\n",
    "#step_list = [0, 1, 2]\n",
    "#step_list = [0] + list(range(4, 30, 5))\n",
    "#step_list = list(range(0, 10, 1))\n",
    "\n",
    "#manyruns_dirnames = ['Wrandom0_gamma%.2f_10k_p3_M100' % a for a in gamma_list]\n",
    "#manyruns_dirnames = ['Wrandom0_gamma%.2f_10k_fixedorderNotOrig_p3_M100' % a for a in gamma_list]\n",
    "#manyruns_dirnames = ['Wrandom1_gamma%.2f_10k_fixedorder_p3_M100' % a for a in gamma_list]\n",
    "manyruns_dirnames = ['Wrandom0_gamma%.2f_10k_periodic_fixedorderV3_p3_M100' % a for a in gamma_list]\n",
    "\n",
    "manyruns_paths = [RUNS_FOLDER + os.sep + 'multicell_manyruns' + os.sep + dirname\n",
    "                  for dirname in manyruns_dirnames]\n",
    "\n",
    "# Step 1) umap (or other dim reduction) kwargs\n",
    "if any([build_dimreduce_dicts, add_control_data, vis_all, pca_assess]):\n",
    "    for n_components in [2]:\n",
    "\n",
    "        for step in step_list:\n",
    "            #n_components = 3\n",
    "            pca_kwargs = PCA_KWARGS.copy()\n",
    "            pca_kwargs['n_components'] = n_components  # TODO don't need to spec 'live', can embed later?\n",
    "            umap_kwargs = UMAP_KWARGS.copy()\n",
    "            umap_kwargs['n_components'] = n_components  # TODO don't need to spec 'live', can embed later?\n",
    "            tsne_kwargs = TSNE_KWARGS.copy()\n",
    "            tsne_kwargs['n_components'] = n_components  # TODO don't need to spec 'live', can embed later?\n",
    "            # modify pca settings\n",
    "            # modify umap settings\n",
    "            #umap_kwargs['unique'] = True\n",
    "            #umap_kwargs['n_neighbors'] = 100\n",
    "            umap_kwargs['min_dist'] = 0.25\n",
    "            umap_kwargs['spread'] = 1.0\n",
    "            #umap_kwargs['metric'] = 'euclidean'\n",
    "            # modify tsne settings\n",
    "            #tsne_kwargs['perplexity'] = 100\n",
    "\n",
    "            # Modify filename suffix for dimreduce pkl and plots\n",
    "            fmod = ''\n",
    "            if step is not None:\n",
    "                fmod += '_step%d' % step\n",
    "            fmod += '_F=' + '+'.join(REDUCERS_TO_USE)\n",
    "            fmod += '_dim%d_seed%d' % (umap_kwargs['n_components'],\n",
    "                                       umap_kwargs['random_state'])\n",
    "            if use_01:\n",
    "                fmod += '_use01'\n",
    "            if nsubsample is not None:\n",
    "                fmod += '_nn%d' % nsubsample\n",
    "            if jitter_scale > 0:\n",
    "                fmod += '_jitter%.4f' % jitter_scale\n",
    "            if 'umap' in REDUCERS_TO_USE:\n",
    "                if umap_kwargs['metric'] != 'euclidean':\n",
    "                    fmod += '_%s' % umap_kwargs['metric']\n",
    "                if umap_kwargs['init'] != 'spectral':\n",
    "                    fmod += '_%s' % umap_kwargs['init']\n",
    "                if umap_kwargs['n_neighbors'] != 15:\n",
    "                    fmod += '_nbor%d' % umap_kwargs['n_neighbors']\n",
    "                if umap_kwargs['min_dist'] != 0.1:\n",
    "                    fmod += '_dist%.2f' % umap_kwargs['min_dist']\n",
    "                if umap_kwargs['spread'] != 1.0:\n",
    "                    fmod += '_spread%.2f' % umap_kwargs['spread']\n",
    "                if umap_kwargs['unique']:\n",
    "                    fmod += '_unique'\n",
    "            if 'tsne' in REDUCERS_TO_USE:\n",
    "                if tsne_kwargs['perplexity'] != 30.0:\n",
    "                    fmod += '_perplex%.2f' % tsne_kwargs['perplexity']\n",
    "\n",
    "            # Step 2) make/load data\n",
    "            datasets = {i: {'label': manyruns_dirnames[i],\n",
    "                            'path': manyruns_paths[i]}\n",
    "                        for i in range(len(manyruns_dirnames))}\n",
    "\n",
    "            for idx in range(len(manyruns_dirnames)):\n",
    "                fpath = manyruns_paths[idx] + os.sep + 'dimreduce' \\\n",
    "                        + os.sep + 'dimreduce%s.z' % fmod\n",
    "                if os.path.isfile(fpath):\n",
    "                    print('Exists already, loading: %s' % fpath)\n",
    "                    fcontents = joblib.load(fpath)  # just load file if it exists\n",
    "                    datasets[idx] = fcontents\n",
    "                else:\n",
    "                    print('Dim. reduction on manyruns: %s' % manyruns_dirnames[idx])\n",
    "                    datasets[idx] = make_dimreduce_object(\n",
    "                        datasets[idx], nsubsample=nsubsample, flag_control=False,\n",
    "                        use_01=True, jitter_scale=jitter_scale,\n",
    "                        umap_kwargs=umap_kwargs, tsne_kwargs=tsne_kwargs, pca_kwargs=pca_kwargs,\n",
    "                        step=step)\n",
    "                    save_dimreduce_object(datasets[idx], fpath)  # save to file (joblib)\n",
    "\n",
    "            if add_control_data:\n",
    "                print('adding control data...')\n",
    "                total_spins_0 = datasets[0]['total_spins']\n",
    "                num_runs_0 = datasets[0]['num_runs']\n",
    "\n",
    "                # add control data into the dict of datasets\n",
    "                control_X = generate_control_data(total_spins_0, num_runs_0)\n",
    "                control_folder = RUNS_FOLDER + os.sep + 'multicell_manyruns' + os.sep + 'control'\n",
    "                control_fpath = control_folder + os.sep + \\\n",
    "                                'dimreduce' + os.sep + 'dimreduce%s.z' % fmod\n",
    "\n",
    "                datasets[-1] = {\n",
    "                    'data': control_X,\n",
    "                    'label': 'control (coin-flips)',\n",
    "                    'num_runs': num_runs_0,\n",
    "                    'total_spins': total_spins_0,\n",
    "                    'energies': np.zeros((num_runs_0, 5)),\n",
    "                    'path': control_folder\n",
    "                }\n",
    "                datasets[-1] = make_dimreduce_object(\n",
    "                    datasets[-1], flag_control=True,\n",
    "                    nsubsample=nsubsample, jitter_scale=jitter_scale, use_01=use_01,\n",
    "                    umap_kwargs=umap_kwargs, tsne_kwargs=tsne_kwargs, pca_kwargs=pca_kwargs)\n",
    "                save_dimreduce_object(datasets[-1], control_fpath)  # save to file (joblib)\n",
    "\n",
    "            # Step 3) vis data\n",
    "            if vis_all:\n",
    "                for idx in range(0, len(manyruns_dirnames)):\n",
    "                    plotly_express_embedding_LOCAL(\n",
    "                        datasets[idx], fmod=fmod, show=False,\n",
    "                        step=step)\n",
    "                    plotly_express_embedding_LOCAL(\n",
    "                        datasets[idx], fmod=fmod, color_by_index=True, show=False,\n",
    "                        step=step)\n",
    "                    plotly_express_embedding_LOCAL(\n",
    "                        datasets[idx], fmod=fmod, as_landscape=True, show=False,\n",
    "                        step=step)\n",
    "                    #plotly_express_embedding(\n",
    "                    #    datasets[idx], fmod=fmod, as_landscape=True, show=False, surf=True)\n",
    "                    if pca_assess:\n",
    "                        pca_assess_dataset(datasets[idx], fmod=fmod, show=False)\n",
    "\n",
    "                if add_control_data:\n",
    "                    plotly_express_embedding_LOCAL(datasets[-1], fmod=fmod, color_by_index=True)\n",
    "                    if pca_assess:\n",
    "                        pca_assess_dataset(datasets[-1], fmod=fmod, show=False)\n",
    "\n",
    "            # Step 3) plot special indices of the multicell state\n",
    "            if plot_specific_points:\n",
    "                #agg_indices = [2611, 2289]\n",
    "                agg_indices = [481, 4774]\n",
    "                outdir = RUNS_FOLDER + os.sep + 'explore' + os.sep + 'plot_specific_points'\n",
    "\n",
    "                for idx in range(0, len(manyruns_dirnames)):\n",
    "\n",
    "                    multicell = datasets[idx]['multicell_template']\n",
    "\n",
    "                    for agg_index in agg_indices:\n",
    "                        # pull relevant info from subdict\n",
    "                        X = datasets[idx]['data'][agg_index, :]\n",
    "                        step_hack = 0  # TODO care this will break if class has time-varying applied field\n",
    "                        multicell.graph_state_arr[:, step_hack] = X[:]\n",
    "                        #assert np.array_equal(multicell_template.field_applied, np.zeros((total_spins, multicell_template.total_steps)))\n",
    "                        plot_given_multicell(multicell, step_hack, agg_index, outdir)\n",
    "\n",
    "# Step 4) eval check of Jij\n",
    "if check_evals:\n",
    "    for idx, dirpath in enumerate(manyruns_paths):\n",
    "        fpath_pickle = dirpath + os.sep + 'multicell_template.pkl'\n",
    "        with open(fpath_pickle, 'rb') as pickle_file:\n",
    "            multicell_template = pickle.load(pickle_file)  # unpickling multicell object\n",
    "\n",
    "        J_multicell = multicell_template.matrix_J_multicell\n",
    "        evals, evecs = sorted_eig(J_multicell, take_real=True)\n",
    "        plt.scatter(range(len(evals)), evals)\n",
    "        plt.title(r'Spectrum of $J_{\\mathrm{multicell}}$ for: %s' % os.path.basename(dirpath))\n",
    "        plt.xlabel('rank of $\\lambda$')\n",
    "        plt.ylabel('$\\lambda$')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def axis_bounds(embedding):\n",
    "    left, right = embedding.T[0].min(), embedding.T[0].max()\n",
    "    bottom, top = embedding.T[1].min(), embedding.T[1].max()\n",
    "    adj_h, adj_v = (right - left) * 0.1, (top - bottom) * 0.1\n",
    "    return [left - adj_h, right + adj_h, bottom - adj_v, top + adj_v]\n",
    "\n",
    "num_rows = 2\n",
    "num_cols = 8\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 10))\n",
    "ax_bound = axis_bounds(\n",
    "    np.vstack( [datasets[i]['algos']['umap']['embedding'] for i in range(len(gamma_list))] )\n",
    ")\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    if i<len(gamma_list):\n",
    "        print(i)\n",
    "        #current_target = ordered_target[150 * i:min(ordered_target.shape[0], 150 * i + 400)]\n",
    "        Xd = datasets[i]['algos']['umap']['embedding']\n",
    "        energies = datasets[i]['energies'][:,0]\n",
    "        print(Xd.shape)\n",
    "        ax.set_title(gamma_list[i])\n",
    "        #ax.scatter(Xd[:,0], Xd[:,1], s=1, cmap=\"Spectral\")\n",
    "        ax.scatter(Xd[:,0], Xd[:,1], s=1, c=energies, cmap=\"Spectral_r\")\n",
    "        ax.axis(ax_bound)\n",
    "        ax.set(xticks=[], yticks=[])\n",
    "    else:\n",
    "        fig.delaxes(ax)\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "#plt.savefig('aligned%d_gammas%d.jpg' % (nn, len(gamma_list)))\n",
    "plt.savefig('Subplots%d%s.jpg' % (len(gamma_list), fmod))\n",
    "#plt.savefig('Subplots%d%s.pdf' % (len(gamma_list), fmod))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 7))\n",
    "ax = plt.gca()\n",
    "\n",
    "i = 3\n",
    "Xd = datasets[i]['algos']['umap']['embedding']\n",
    "energies = datasets[i]['energies'][:,0]\n",
    "print(Xd.shape)\n",
    "ax.set_title(gamma_list[i])\n",
    "\n",
    "#ax.scatter(Xd[:,0], Xd[:,1], s=1, cmap=\"Spectral\")\n",
    "#ax.scatter(Xd[:,0], Xd[:,1], s=1, c=energies, cmap=\"RdYlBu_r\")\n",
    "sc = ax.scatter(Xd[:,0], Xd[:,1], s=5, c=energies, cmap=\"Spectral_r\", alpha=1.0, edgecolor='k', linewidths=0.0)\n",
    "#cbar = plt.colorbar(sc)\n",
    "cbar.ax.tick_params(size=0)\n",
    "\n",
    "#ax.axis(ax_bound)\n",
    "ax.set(xticks=[], yticks=[])\n",
    "#plt.tight_layout()\n",
    "#plt.savefig('Subplots%d%s.jpg' % (len(gamma_list), fmod))\n",
    "#plt.savefig('Subplots%d%s.pdf' % (len(gamma_list), fmod))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_rows = 2\n",
    "num_cols = 9\n",
    "fig, axs = plt.subplots(num_rows, num_cols, figsize=(20, 10))\n",
    "#ax_bound = axis_bounds(\n",
    "#    np.vstack( [datasets[i]['algos']['umap']['embedding'] for i in range(len(gamma_list))] )\n",
    "#)\n",
    "\n",
    "\n",
    "picks = list(range(len(gamma_list)))\n",
    "picks = [0, 3, 4, 6, 7, 8, 9, 11, 13]\n",
    "\n",
    "for j, ax in enumerate(axs.flatten()):\n",
    "    if j < len(picks):\n",
    "        print(j)\n",
    "        i = picks[j]\n",
    "        #current_target = ordered_target[150 * i:min(ordered_target.shape[0], 150 * i + 400)]\n",
    "        Xd = datasets[i]['algos']['umap']['embedding']\n",
    "        energies = datasets[i]['energies'][:,0]\n",
    "        print(Xd.shape)\n",
    "        ax.set_title(gamma_list[i])\n",
    "        #ax.scatter(Xd[:,0], Xd[:,1], s=1, cmap=\"Spectral\")\n",
    "        ax.scatter(Xd[:,0], Xd[:,1], s=1, c=energies, cmap=\"Spectral_r\")\n",
    "        #ax.axis(ax_bound)\n",
    "        ax.set(xticks=[], yticks=[])\n",
    "    else:\n",
    "        fig.delaxes(ax)\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "#plt.savefig('aligned%d_gammas%d.jpg' % (nn, len(gamma_list)))\n",
    "plt.savefig('PicksSubplots%d%s.jpg' % (len(gamma_list), fmod), dpi=300)\n",
    "#plt.savefig('Subplots%d%s.pdf' % (len(gamma_list), fmod))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
